---
title: Linear_Regression
date: 2018-04-19 10:01:48
tags:
- Machine learning
- Algorithm
category:
- Machine learning
- Algorithm
mathjax: true
---

## 基本形式
$$f(x)=\omega^Tx+b$$
线性回归试图学得 $f(x_i)=\omega^Tx_i+b$ ,使得 $f(x_i)\approx y_i$ 

## 一元线性回归
使用最小二乘法（least square method）进行参数估计（parameter estimation）
{% math %}$(\omega^*,b^*)=arg min\sum_{i=1}^m{(f(x_i)-y_i)^2}=arg min\sum_{i=1}^m{(y_i-\omegax_i-b)^2}${% endmath %}

基于上式对$\omega和b$求偏导，并令其为0，可得到$\omega和b$的最有闭式解

## 多元线性回归（multivariate linear regression）
更一般的，样本有多个属性描述（多个特征）
简化一下公式，可以把$\omega和b$吸收入向量形式$\hat{\omega}=(\omega;b)$，把数据集D表示成为一个m*（d+1）矩阵
{% math %}X=\begin{bmatrix}
{x_{11}}&{x_{12}}&{\cdots}&{x_{1n}}&{1}\\
{x_{21}}&{x_{22}}&{\cdots}&{x_{2n}}&{1}\\
{\vdots}&{\vdots}&{\ddots}&{\vdots}&{\vdots}\\
{x_{m1}}&{x_{m2}}&{\cdots}&{x_{mn}}&{1}\\
\end{bmatrix}{% endmath %}

此时，$f(x_i)=\omega^Tx_i+b_i=X\hat{\omega}$







